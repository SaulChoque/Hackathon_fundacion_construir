import json
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch


def procesar_resultados(archivo_json):
    """formato JSON con:
    - Filtro de calidad de contenido
    - Priorizaci√≥n de fuentes clave
    - Normalizaci√≥n de texto"""
    
    with open(archivo_json, 'r', encoding='utf-8') as f:
        datos = json.load(f)
    
    resultados = []
    fuentes_prioritarias = ["infobae.com", "lapatria.bo", "lostiempos.com"]
    
    for item in datos:
        # Filtros b√°sicos
        if not item.get("resumen") or len(item["resumen"]) < 150:
            continue
            
        # Normalizaci√≥n
        contenido = item["resumen"]
        if "Fotograf√≠a de archivo" in contenido:
            contenido = contenido.split("Fotograf√≠a de archivo")[0]
        
        # Priorizar fuentes confiables
        prioridad = 2 if any(fp in item["url"] for fp in fuentes_prioritarias) else 1
        
        resultados.append({
            "titulo": item["titulo"],
            "fuente": item["fuente"],
            "contenido": contenido[:2000],  # Limitar tama√±o
            "prioridad": prioridad,
            "fecha": item.get("resumen", "").split(" ")[0]  # Extrae fecha del resumen
        })
    
    # Ordenar por prioridad y longitud de contenido
    return sorted(
        resultados,
        key=lambda x: (-x["prioridad"], -len(x["contenido"]))
    

# ==============================
# 2. GENERADOR DE SHORTS OPTIMIZADO
# ==============================
def generar_shorts(datos, tema):
    """Genera guiones ultra-concisos para YouTube Shorts con:
    - Estructura cronometrada exacta
    - Datos espec√≠ficos de tus fuentes
    - Adaptaci√≥n al formato vertical"""
    
    # Preparar contexto para IA (top 3 fuentes)
    contexto = "\n\n".join(
        f"üìå {item['titulo']} ({item['fuente']}, {item.get('fecha', 's/f')}):\n"
        f"{item['contenido'][:300]}..."
        for item in datos[:3]
    )

    prompt = f"""**Instrucciones exactas para YouTube Short (30-60 segundos):**

**Tema:** {tema}
**Formato OBLIGATORIO:**
[0:00-0:04] üé£ HOOK: Afirmaci√≥n impactante (usar n√∫meros/controversia)
[0:04-0:12] üéØ CONTEXTO: 1 frase sobre el candidato/elecci√≥n
[0:12-0:30] üí° PROPUESTAS: 2 M√ÅXIMO (con datos concretos)
[0:30-0:50] üî• IMPACTO: 1 consecuencia o dato pol√©mico
[0:50-1:00] ‚ùì CTA: Pregunta para comentarios + emoji

**Fuentes disponibles (usar datos exactos):**
{contexto}

**Ejemplo real basado en fuentes:**
[Hook] "¬°Doria Medina quiere ELIMINAR el SENADO! (Ahorro: $200M/a√±o)"
[Contexto] "Candidato opositor lidera encuestas para 2025"
[Propuestas] 
1. Autonom√≠as econ√≥micas regionales
2. Voto electr√≥nico desde 2026
[Impacto] "Seg√∫n Infobae: 68% apoya pero congreso rechaza"
[CTA] "¬øEs viable este plan? üëá"

**Guion a generar (seguid el formato):**"""
    
    # Configuraci√≥n para respuestas ultra-cortas
    tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-v0.1")
    model = AutoModelForCausalLM.from_pretrained(
        "mistralai/Mistral-7B-v0.1",
        torch_dtype=torch.float16,
        device_map="auto"
    )
    
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
    outputs = model.generate(
        **inputs,
        max_new_tokens=300,  # Extremadamente conciso
        temperature=0.7,
        top_p=0.9,
        do_sample=True,
        repetition_penalty=1.2
    )
    
    guion = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return guion.split("**Guion a generar:**")[-1].strip()

# ==============================
# 3. EJECUCI√ìN PRINCIPAL
# ==============================
if __name__ == "__main__":
    # Configuraci√≥n
    TEMA = "Samuel Doria Medina: Propuestas clave 2025"
    ARCHIVO_JSON = "resultados_mejorados_Webscrapper_example.json"  # Tu archivo actualizado
    
    # Paso 1: Procesar datos
    print("üìä Procesando resultados JSON...")
    datos_procesados = procesar_resultados(ARCHIVO_JSON)
    
    if not datos_procesados:
        print("‚ùå No hay datos v√°lidos para generar el guion")
        exit()
    
    # Paso 2: Generar guion para Shorts
    print("üé¨ Generando guion para YouTube Shorts...")
    guion = generar_shorts(datos_procesados, TEMA)
    
    # Guardar resultado
    with open("shorts_final.txt", "w", encoding="utf-8") as f:
        f.write(f"# GUION SHORT - {TEMA}\n\n")
        f.write(guion)
    
    print("\n‚úÖ ¬°Guion generado con √©xito!")
    print(f"- Archivo guardado: shorts_final.txt")
    print("\n--- EXTRACTO ---")
    print(guion[:500] + "...")
